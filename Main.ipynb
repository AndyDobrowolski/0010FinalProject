{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satisfied-pottery",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-plymouth",
   "metadata": {},
   "source": [
    "For our presentation we decided to focus on the environmental side of the neighborhoods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just import commands.\n",
    "import pandas            as pd\n",
    "import numpy             as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-process",
   "metadata": {},
   "source": [
    "### ----- Yuqing -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-police",
   "metadata": {},
   "source": [
    "### Illegal Dump Sites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-farmer",
   "metadata": {},
   "source": [
    "In order to find the most enviromentally firendly neighborhood. I choose the data of the illegal dump sites in the Allegheny County."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first ten rows of the data\n",
    "dumps = pd.read_csv('Datasets\\illegaldumpsites.csv')\n",
    "dumps.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-grade",
   "metadata": {},
   "source": [
    "Since the data contains all the places in Allegeny County, I should pick out the data of Pittsburgh. What's more, I found some illegal sites were already been completed. I assume they had been removed. So I also need to delete the sites that status are completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick out the city of Pittsburgh and incompleted dump sites\n",
    "dump_in_pitts = dumps.loc[dumps['City'] == 'Pittsburgh']\n",
    "dump_in_pitts2 = dump_in_pitts.loc[dumps['Status'] != 'Completed']\n",
    "dump_in_pitts2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed unecessary columns and leave 'Status' as 'count' to calculate the number of dump sites in each neighborhood\n",
    "clean_dump_in_pitts = dump_in_pitts2.drop(['site_name', 'City', 'location_description','latitude', 'longitude', 'estimated_tons','Unnamed: 8'], axis=1)\n",
    "# group the count from smallest to largest\n",
    "dump_in_neighborhoods = clean_dump_in_pitts.groupby('Neighborhood').size().sort_values()\n",
    "dump_in_neighborhoods.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-rehabilitation",
   "metadata": {},
   "source": [
    "From the data above, I can find that from 'Beltzhoover'to 'Perry South' neighborhood, the number of dump sites are over 10. So these neighborhoods can be wiped from our consideration about the most enviromentally friendly neighborhood in Pittsburgh.\n",
    "\n",
    "I graph a bar chart to show the numbers of dump sites in each neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_in_neighborhoods.plot.bar(figsize=[30,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-formation",
   "metadata": {},
   "source": [
    "I also graph a map of the dump sites in each neighborhood to enhance visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = clean_dump_in_pitts.groupby('Neighborhood').count()\n",
    "neighborhoods = geopandas.read_file(\"Neighborhoods/Neighborhoods_.shp\")\n",
    "bin_map = neighborhoods.merge(new, how='left', left_on='hood', right_on='Neighborhood')\n",
    "bin_map.plot(column='Status',\n",
    "             cmap='GnBu',\n",
    "             edgecolor=\"black\",\n",
    "             legend=True,\n",
    "             legend_kwds={'label':\"Number of illegal dump sites\"},\n",
    "             figsize=(15,10),\n",
    "             missing_kwds={\"color\": \"lightgrey\"}\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-stanley",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-fairy",
   "metadata": {},
   "source": [
    "### ----- Kenny -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-ordinary",
   "metadata": {},
   "source": [
    "### Smart Trash in Our Neighborhoods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-slope",
   "metadata": {},
   "source": [
    "One of our main focal points in determining the best neighborhood is analyzing the environmental aspects of each area and trying to find some particular attributes that we would desire in our ideal neighborhood. In this case, it is the idea of general cleanliness of the neighborhood. Nobody wants to live in an area where the streets are full of litter with sidewalks cluttered with trash. One proposed method is the idea of \"smart waste management\" and its implementation of smart trash cans. Pittsburgh has adopted this system with the deployment of trash cans that monitor the volume of trash in each bin. This allows for munipalities and trash management workers to optimize their time to empty bins that are more full compared to rotating on a weekly schedule. While this can not account for those who litter ignorantly, it does minimize the excess waste as trash bins are more likely to be empty for use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-dylan",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-internet",
   "metadata": {},
   "source": [
    "To start, we will take a brief look at the information provided by the dataset in the TrashContainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extensive-kazakhstan",
   "metadata": {},
   "outputs": [],
   "source": [
    "containers  = pd.read_csv('Datasets\\TrashContainers.csv')\n",
    "containers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-onion",
   "metadata": {},
   "source": [
    "Certain columns such as receptacle model id,the dates, and fire zones are not particularly relevant in our analysis as we are going to focus on concentrated areas of smart trash containers. We can drop these columns to refine the data a little bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "containers.drop('receptacle_model_id', inplace=True, axis=1)\n",
    "containers.drop('assignment_date', inplace=True, axis=1)\n",
    "containers.drop('last_updated_date', inplace=True, axis=1)\n",
    "containers.drop('fire_zone', inplace=True, axis=1)\n",
    "containers.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-defensive",
   "metadata": {},
   "source": [
    "This allows use to see what specifications we are working with in the smart trash dataset. The next step is to sum up the amount of smart trash cans in each neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = containers.groupby('neighborhood').count() # forming a dataset that is used to produce a choropleth map of the bins\n",
    "\n",
    "containers['neighborhood'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-liberty",
   "metadata": {},
   "source": [
    "This is getting showing the numerical value of the sum of trash bins in each neighborhood. I want to visualize this into a choropleth graph to see the concentrations of smart trash bins with the corresponding neighborhood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = geopandas.read_file(\"Neighborhoods/Neighborhoods_.shp\")\n",
    "bin_map = neighborhoods.merge(bins, how='left', left_on='hood', right_on='neighborhood')\n",
    "bin_map.plot(column='ward',\n",
    "             cmap='OrRd',\n",
    "             edgecolor=\"black\",\n",
    "             legend=True,\n",
    "             legend_kwds={'label':\"Number of Smart Trash Bins\"},\n",
    "             figsize=(15,10),\n",
    "             missing_kwds={\"color\": \"lightgrey\"}\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-republic",
   "metadata": {},
   "source": [
    "\n",
    "In the end, Shadyside is the best neighborhood based solely on the concentration of the smart trash bins located there. This does not come as a surprise as Shadyside is quite reknown for its attractive and cleanliness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-graph",
   "metadata": {},
   "source": [
    "### ----- Anderis -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-zoning",
   "metadata": {},
   "source": [
    "Pittsburgh is a pretty large city. Despite all the high rises and parking complexes, there are still quite a lot of trees throughout each neighborhood of the city. For my part of the Project I am going to be looking at the number of (legally documented and cared for) trees that are within each neighborhood. Throughout this file will have information on the numerics of these trees, as well as their general wellbeing. All of these factors will go into my metric to decide which neighborhood is truly the best in Pittsburgh. (based on this arbitrary metric :D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-shift",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing datasets and changing some of the indexes to better fit my needs\n",
    "trees    = pd.read_csv('Datasets\\Trees.csv', low_memory=False)\n",
    "fname    = \"Datasets/Neighborhoods.geojson\"\n",
    "pitt_map = geopandas.read_file(fname)\n",
    "pitt_map = pitt_map.rename(columns={'Neighborhood_2010_HOOD' : 'Neighborhood'})\n",
    "df       = pd.DataFrame(data=trees['neighborhood'].value_counts(sort=False))\n",
    "df       = df.rename(columns={'neighborhood' : 'count'}).reset_index()\n",
    "df       = df.rename(columns={'index' : 'neighborhood'})\n",
    "\n",
    "# Sorted both datasets so they would match up\n",
    "pitt_map = pitt_map.sort_values(by='Neighborhood').reset_index()\n",
    "df       = df.sort_values(by='neighborhood').reset_index()\n",
    "\n",
    "# merges the two data sets together with a concatination.\n",
    "frame    = [pitt_map,df]\n",
    "merged   = pd.concat(frame, axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "# general variables to help setup the Choropleth map\n",
    "variable   = 'count'\n",
    "vmin, vmax = 0, 5073\n",
    "fig, ax    = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "# turns off the axis lines\n",
    "ax.axis('off')\n",
    "\n",
    "# sets up the legend for the map\n",
    "sm   = plt.cm.ScalarMappable(cmap='Greens', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "# writes the map\n",
    "merged.plot(column=variable, cmap='Greens', linewidth=0.8, vmin=vmin , vmax=vmax , ax=ax, edgecolor='0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-beast",
   "metadata": {},
   "source": [
    "This is the first of my Choropleth maps!\n",
    "\n",
    "This one is quite simple, it just maps out all the different neighborhoods and colors them in based on total number of trees within the neighborhood. Obviously Squirrel Hilll South, the largest neighborhood, is top of the list on this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists out the neighborhoods with the top 10 highest tree counts.\n",
    "merged[['neighborhood','count']].sort_values(by='count', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-hollow",
   "metadata": {},
   "source": [
    "Now do we get all the information we want from that map? of course not! Obviously the alrgest neighborhood has the most amount of trees. So lets try incorporating the areas of the neighborhoods into the calculations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the amount of trees per square kilometer within each neighborhood\n",
    "TSK = (merged['count']).div(merged['SHAPE_Area'].mul(100000)).to_frame('Trees per Square Kilometer')\n",
    "\n",
    "# Concatinates the datasets. Be prepared for lots of mergedx variables.. I'm not the best at naming :D\n",
    "merged2 = pd.concat([merged, TSK], axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "# once again just variable stuff for the map\n",
    "variable = 'Trees per Square Kilometer'\n",
    "vmin,vmax = 10, 151\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.axis('off')\n",
    "\n",
    "# legend stuff\n",
    "sm = plt.cm.ScalarMappable(cmap='Greens', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "# draws out the map\n",
    "merged2.plot(column=variable, cmap='Greens', linewidth=0.8, vmin=vmin , vmax=vmax , ax=ax, edgecolor='0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-bottom",
   "metadata": {},
   "source": [
    "Now the map is looking a lot different! accounting for the total number of trees mixed with the area has made it so Allegheny Center, a decently small neighborhood, is shown to have the highest density of trees per square kilometer. In fact Squirrel Hill, our highest before, does not even fall into the top 10 now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2[['neighborhood','Trees per Square Kilometer']].sort_values(by='Trees per Square Kilometer', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-roads",
   "metadata": {},
   "source": [
    "Our new top 10 has a lot of smaller neighborhoods starting to gain in spots. Of course not every tree is created equal. So how do all of these neighborhoods fair when the health of the trees are a concern?\n",
    "\n",
    "The beginning of this next section of code uses the conditions of the trees in order to calulate a total number of healthy trees. I used a scoring system from Dead equaling -2 trees, all the way up to Excellent equalling 1.4 trees. This way neighborhoods that take more care of their trees gain more of an advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to hold the condition values.\n",
    "cond_list = []\n",
    "\n",
    "# code to ammend a list with all the values based on condition of the trees.\n",
    "for x in trees['condition']:\n",
    "    if x != x:\n",
    "        cond_list.append(-1)\n",
    "    elif x == 'Dead':\n",
    "        cond_list.append(-2)\n",
    "    elif x == 'Critical':\n",
    "        cond_list.append(0.2)\n",
    "    elif x == 'Poor':\n",
    "        cond_list.append(0.4)\n",
    "    elif x == 'Fair':\n",
    "        cond_list.append(0.6)\n",
    "    elif x == 'Good':\n",
    "        cond_list.append(1.0)\n",
    "    elif x == 'Very Good':\n",
    "        cond_list.append(1.2)\n",
    "    elif x == 'Excellent':\n",
    "        cond_list.append(1.4)\n",
    "    else:\n",
    "        cond_list.append(x)\n",
    "\n",
    "# adding the values into a DataFrame\n",
    "cond_val = pd.DataFrame().append(cond_list)\n",
    "cond_val.columns = ['Tree Health']\n",
    "\n",
    "# merging the dataframe into the Tree.csv file DataFrame\n",
    "tree_merge = pd.concat([trees,cond_val], axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "# groups all of the different values based on the neighborhood they reside and sums the scores together.\n",
    "tree_health = tree_merge.groupby(by='neighborhood').sum().sort_values('neighborhood', ascending = True)['Tree Health']\n",
    "\n",
    "# flips the columns and rows to better match later DataFrames.\n",
    "tree_health = pd.DataFrame().append(tree_health).transpose()\n",
    "tree_health = tree_health.reset_index()\n",
    "\n",
    "# Hey look! another mergex variable. Sadly, theres still more later.\n",
    "merged3 = pd.concat([merged2,tree_health], axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "# more empty lists to store things!\n",
    "count_list = []\n",
    "health_list = []\n",
    "calc_list = []\n",
    "\n",
    "# fills the first two lists with the original tree counts and the sum of Tree Health.\n",
    "for x in merged3['count']:\n",
    "    count_list.append(x)\n",
    "for x in merged3['Tree Health']:\n",
    "    health_list.append(x)\n",
    "\n",
    "# fills a list with the calulations of what percent of trees are healthy within each neighborhood.\n",
    "for x in range(90):\n",
    "    calc_list.append((((health_list[x]) / (count_list[x]))) * 100)\n",
    "\n",
    "# puts it into a DataFrame\n",
    "perc_health = pd.DataFrame().append(calc_list)\n",
    "perc_health.columns = ['Tree Health Percentage']\n",
    "\n",
    "# Another mergex variable!\n",
    "merged4 = pd.concat([merged3,perc_health], axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "# variables for the Choropleth map :D\n",
    "variable = 'Tree Health Percentage'\n",
    "vmin,vmax = 0, 100\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.axis('off')\n",
    "\n",
    "# Legends never die\n",
    "sm = plt.cm.ScalarMappable(cmap='Greens', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "# makes the map\n",
    "merged4.plot(column=variable, cmap='Greens', linewidth=0.8, vmin=vmin , vmax=vmax , ax=ax, edgecolor='0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-efficiency",
   "metadata": {},
   "source": [
    "So now we have a map based on the percentages of healthy trees within each of the neighborhoods. Some of the neighborhoods did really well with Chartiers City getting an astounding 86.4% on the scale of healthy trees. And while there may be highs like this, Oh there are far, far worse lows. Poor Hays somehow managed to pull of a -200% on the scale of healthy trees. Actually in total 9 of the neighborhoods all scored a negative number for this section. A negative in this case means that they just have more dead trees than alive ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged4[['neighborhood','Tree Health Percentage']].sort_values(by='Tree Health Percentage', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged4[['neighborhood','Tree Health Percentage']].sort_values(by='Tree Health Percentage', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-april",
   "metadata": {},
   "source": [
    "Yeah the low scores for here are abysmal. As another note there was a section of the datasets that had the value \"NaN\" which through looking at the data appeared to coincide with where there were simply stumps left of trees. So stumps are actually classified differently than simply being \"Dead\" within these sets. So the low scores ( expecially Hays ) had a lot of either Dead trees, or Stumps where trees used to be. (well as of like March 7, 2021 when this was last updated)\n",
    "\n",
    "But anyway, we now have the percentage of healthy trees within each neighborhood! so does that mean Chartiers City gets to take home the Golden Tree Crown? Not quite yet. We need to once again account for the area of each of these neighborhoods. Then we will finally be able to crown the Truest Healthy Tree filled neighborhood in Pittsburgh!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dietary-sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates The number of healthy trees per Square Kilometer\n",
    "HTSK = (merged4['Tree Health']).div(merged4['SHAPE_Area'].mul(100000)).to_frame('Health of Trees per Square Kilometer')\n",
    "\n",
    "# hey the final mergex variable. They grow up so fast.\n",
    "merged5 = pd.concat([merged4, HTSK], axis=1, ignore_index=False, sort=False)\n",
    "\n",
    "# more map variables. \n",
    "variable = 'Health of Trees per Square Kilometer'\n",
    "vmin,vmax = 0, 113\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.axis('off')\n",
    "\n",
    "# There have been many legends carried down through these long few days. Legends that one day, the Healthy \n",
    "# trees may soon rise up and take their rightful place among the streets of Pittsburgh.\n",
    "sm = plt.cm.ScalarMappable(cmap='Greens', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "cbar = fig.colorbar(sm)\n",
    "\n",
    "# The Final Map Creation :D\n",
    "merged5.plot(column=variable, cmap='Greens', linewidth=0.8, vmin=vmin , vmax=vmax , ax=ax, edgecolor='0.8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-trace",
   "metadata": {},
   "source": [
    "And now we finally have our winner. It goes to Alleghey Center! This neighborhood has proven to have not only the highest density of trees, but also the highest density of healthy tree too! We can finally crown the best Neighborhood in Pittsburgh based on these arbitrary measurements I have compounded together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged5[['neighborhood','Health of Trees per Square Kilometer']].sort_values(by='Health of Trees per Square Kilometer',ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-instrument",
   "metadata": {},
   "source": [
    "As a bit of bonus information. I already shows one of the lists earlier, but heres the rest of the Worst neighborhoods for each category I tested above! So lets get right into it by starting with tree count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged[['neighborhood','count']].sort_values(by='count', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-final",
   "metadata": {},
   "source": [
    "Next we have the worst in tree density!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2[['neighborhood','Trees per Square Kilometer']].sort_values(by='Trees per Square Kilometer', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-procurement",
   "metadata": {},
   "source": [
    "And finally, the worst of the worst when based on The density of healthy trees they have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-society",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged5[['neighborhood','Health of Trees per Square Kilometer']].sort_values(by='Health of Trees per Square Kilometer',ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-cassette",
   "metadata": {},
   "source": [
    "So the Absolute worst neighborhood for trees is Hays, coming up in last place in 3 out of the 4 different measurements.\n",
    "\n",
    "Thats all for this Data, Hopefully more trees will continue to be placed around the city."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-squad",
   "metadata": {},
   "source": [
    "## Final Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-danger",
   "metadata": {},
   "source": [
    "So we've gone through the data, but which neighborhood truly reigns supreme?\n",
    "To figure that out we did some basic addition by applying a point total from 1-10 based on the placement of each neighborhood in our respective datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-senior",
   "metadata": {},
   "source": [
    "So the overall winnder of the best neighborhood in Pittsburgh (base off of a few arbitrary metrics) is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-orange",
   "metadata": {},
   "source": [
    "# *Drum Roll*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-factory",
   "metadata": {},
   "source": [
    "## East Liberty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-creator",
   "metadata": {},
   "source": [
    "This neighborhood didn't get any number 1 spots on the datasets, but it did make up for it by generally good. Scoring a good number two placement based on Trash Containers and a strong 6th place in number of trees. Waste sites didn't help it's score at all, but it still made managed to come out on top."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-election",
   "metadata": {},
   "source": [
    "## Top 5 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-balance",
   "metadata": {},
   "source": [
    "### East Liberty     - 14\n",
    "### Allegheny Center - 10\n",
    "### Shadyside        - 10\n",
    "### Squirrel Hill S  - 10\n",
    "### Friendship       - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-dancing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
